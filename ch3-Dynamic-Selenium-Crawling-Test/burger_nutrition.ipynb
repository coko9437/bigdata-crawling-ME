{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-09T06:28:15.546632Z",
     "start_time": "2025-09-09T06:28:15.538899Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 17,
   "source": [
    "import time\n",
    "import json\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- 1단계: 모든 햄버거 상품의 고유 ID 수집 ---\n",
    "def get_burger_ids():\n",
    "    \"\"\"롯데리아 브랜드 페이지에 접속하여 모든 버거의 고유 ID를 수집합니다.\"\"\"\n",
    "\n",
    "    # 분기점: [크롬 브라우저 실행] -> [롯데리아 브랜드 메인 페이지 접속]\n",
    "    driver = webdriver.Chrome()\n",
    "    main_url = \"https://www.lotteeatz.com/brand/ria\"\n",
    "    driver.get(main_url)\n",
    "\n",
    "    # 분기점: [자바스크립트가 상품 목록을 로드할 때까지 대기]\n",
    "    # ISMS 인증 사이트이므로, 사람처럼 행동하기 위해 넉넉히 기다립니다.\n",
    "    print(\"페이지 로딩 및 상품 목록 확인 중...\")\n",
    "    time.sleep(20)\n",
    "\n",
    "    # 분기점: [로드된 페이지 소스를 BeautifulSoup으로 분석] -> [상품 ID 추출]\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # 'prod-list' 클래스를 가진 ul 태그 안의 모든 'prod-item' li 태그를 선택\n",
    "    product_list = soup.select('ul.prod-list > li.prod-item')\n",
    "\n",
    "    burger_ids = []\n",
    "    for item in product_list:\n",
    "        try:\n",
    "            # 각 li 태그의 onclick 속성 값(예: \"goBrandDetail('REP_000741')\")을 가져옴\n",
    "            onclick_attr = item.get('onclick')\n",
    "            if onclick_attr and 'goBrandDetail' in onclick_attr:\n",
    "                # 괄호와 따옴표 안의 고유 ID만 정교하게 추출\n",
    "                product_id = onclick_attr.split(\"'\")[1]\n",
    "                burger_ids.append(product_id)\n",
    "        except Exception as e:\n",
    "            print(f\"ID 추출 중 오류 발생: {e}\")\n",
    "\n",
    "    driver.quit() # ID 수집이 끝나면 브라우저를 닫습니다.\n",
    "    print(f\"총 {len(burger_ids)}개의 상품 ID를 수집했습니다.\")\n",
    "    return burger_ids"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T06:28:15.581968Z",
     "start_time": "2025-09-09T06:28:15.570262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 2단계: 각 상품 ID별 상세 정보 수집 ---\n",
    "def get_burger_details(burger_ids):\n",
    "    \"\"\"수집된 상품 ID 리스트를 기반으로 각 상품의 상세 정보를 크롤링합니다.\"\"\"\n",
    "\n",
    "    all_burger_data = []\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # 분기점: [수집된 ID 목록을 하나씩 순회 시작]\n",
    "    for i, product_id in enumerate(burger_ids):\n",
    "        # 분기점: [상세 정보 페이지 URL 조합 및 접속]\n",
    "        detail_url = f\"https://www.lotteeatz.com/products/introductions/{product_id}\"\n",
    "        driver.get(detail_url)\n",
    "\n",
    "        # '착한 크롤러'를 위한 필수 대기 시간\n",
    "        time.sleep(10)\n",
    "\n",
    "        detail_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            # 분기점: [상세 정보 추출 시작]\n",
    "            # 1. 버거 이름\n",
    "            name = detail_soup.select_one('div.prod-tit').text.strip()\n",
    "\n",
    "            # 2. 영양소 정보 (테이블 형태)\n",
    "            nutrition_info = {}\n",
    "            # '영양소 정보' 제목을 찾고, 그 다음에 오는 table을 선택\n",
    "            nutrition_table = detail_soup.find('div', class_='btext-tit', string='영양소 정보').find_next_sibling('div', class_='tbl-info-wrap')\n",
    "            if nutrition_table:\n",
    "                rows = nutrition_table.select('tbody > tr')\n",
    "                for row in rows:\n",
    "                    key = row.select_one('th').text.strip()\n",
    "                    value = row.select_one('td').text.strip()\n",
    "                    nutrition_info[key] = value\n",
    "\n",
    "            # 3. 알러지 정보\n",
    "            allergy_info = \"\"\n",
    "            # '알러지 정보' 제목을 찾고, 그 다음에 오는 p 태그를 선택\n",
    "            allergy_p = detail_soup.find('div', class_='btext-tit', string='알러지 정보').find_next_sibling('p', class_='btext')\n",
    "            if allergy_p:\n",
    "                allergy_info = allergy_p.text.strip()\n",
    "\n",
    "            # 4. (추가) 원산지 정보\n",
    "            origin_info = {}\n",
    "            origin_div = detail_soup.find('div', class_='btext-tit', string='원산지 정보')\n",
    "            if origin_div:\n",
    "                origin_table = origin_div.find_next_sibling('div', class_='tbl-info-wrap')\n",
    "                if origin_table:\n",
    "                    rows = origin_table.select('tbody > tr')\n",
    "                    for row in rows:\n",
    "                        key = row.select_one('th').text.strip()\n",
    "                        value = row.select_one('td').text.strip()\n",
    "                        origin_info[key] = value\n",
    "\n",
    "            # 분기점: [추출된 정보를 딕셔너리로 통합 후 최종 리스트에 추가]\n",
    "            burger_data = {\n",
    "                \"id\": product_id,\n",
    "                \"name\": name,\n",
    "                \"nutrition\": nutrition_info,\n",
    "                \"allergy\": allergy_info,\n",
    "                \"origin\": origin_info\n",
    "            }\n",
    "            all_burger_data.append(burger_data)\n",
    "\n",
    "            print(f\"({i+1}/{len(burger_ids)}) ✅ '{name}' 정보 수집 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"({i+1}/{len(burger_ids)}) ❌ ID '{product_id}' 정보 수집 중 오류 발생: {e}\")\n",
    "\n",
    "    driver.quit() # 모든 작업이 끝나면 브라우저를 닫습니다.\n",
    "    return all_burger_data"
   ],
   "id": "57bc7910643eba1a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T06:28:15.596213Z",
     "start_time": "2025-09-09T06:28:15.589210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3단계: 데이터 저장 ---\n",
    "def save_data(data):\n",
    "    \"\"\"수집된 데이터를 JSON과 CSV 파일로 저장합니다.\"\"\"\n",
    "    # JSON 저장\n",
    "    with open(\"lotte_eatz_burgers.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    print(\"✅ JSON 파일 저장 완료: lotte_eatz_burgers.json\")\n",
    "\n",
    "    # CSV 저장을 위해 데이터 평탄화\n",
    "    csv_data = []\n",
    "    for item in data:\n",
    "        # 영양정보와 원산지 정보를 보기 좋게 문자열로 변환\n",
    "        nutrition_str = \", \".join([f\"{k}: {v}\" for k, v in item['nutrition'].items()])\n",
    "        origin_str = \", \".join([f\"{k}: {v}\" for k, v in item['origin'].items()])\n",
    "\n",
    "        csv_data.append([\n",
    "            item['id'],\n",
    "            item['name'],\n",
    "            nutrition_str,\n",
    "            item['allergy'],\n",
    "            origin_str\n",
    "        ])\n",
    "\n",
    "    # CSV 저장\n",
    "    with open(\"lotte_eatz_burgers.csv\", \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['ID', '이름', '영양정보', '알러지정보', '원산지정보'])\n",
    "        writer.writerows(csv_data)\n",
    "    print(\"✅ CSV 파일 저장 완료: lotte_eatz_burgers.csv\")"
   ],
   "id": "f23df8c2b0faefdf",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T06:28:40.042432Z",
     "start_time": "2025-09-09T06:28:15.606137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 메인 실행 블록 ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. 상품 ID 수집\n",
    "    product_ids = get_burger_ids()\n",
    "\n",
    "    # 2. 상세 정보 수집\n",
    "    if product_ids:\n",
    "        burger_details = get_burger_details(product_ids)\n",
    "\n",
    "        # 3. 데이터 저장\n",
    "        if burger_details:\n",
    "            save_data(burger_details)\n",
    "            print(\"\\n🎉 모든 작업이 성공적으로 완료되었습니다!\")"
   ],
   "id": "7541dd570ce9c2b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페이지 로딩 및 상품 목록 확인 중...\n",
      "총 0개의 상품 ID를 수집했습니다.\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
